{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8304551e",
   "metadata": {},
   "source": [
    "****Linear regression using PyTorch built in functions****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e03861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2586b731",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = np.array([[73, 67, 43], [91, 88, 64], [87, 134, 58], \n",
    "                   [102, 43, 37], [69, 96, 70], [73, 67, 43], \n",
    "                   [91, 88, 64], [87, 134, 58], [102, 43, 37], \n",
    "                   [69, 96, 70], [73, 67, 43], [91, 88, 64], \n",
    "                   [87, 134, 58], [102, 43, 37], [69, 96, 70]], \n",
    "                  dtype='float32')\n",
    "\n",
    "target = np.array([[56, 70], [81, 101], [119, 133], \n",
    "                    [22, 37], [103, 119], [56, 70], \n",
    "                    [81, 101], [119, 133], [22, 37], \n",
    "                    [103, 119], [56, 70], [81, 101], \n",
    "                    [119, 133], [22, 37], [103, 119]], \n",
    "                   dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2bea6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.from_numpy(input)\n",
    "target = torch.from_numpy(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d798ab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aed85798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 73.,  67.,  43.],\n",
       "         [ 91.,  88.,  64.],\n",
       "         [ 87., 134.,  58.]]),\n",
       " tensor([[ 56.,  70.],\n",
       "         [ 81., 101.],\n",
       "         [119., 133.]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = TensorDataset(input,target)\n",
    "train_ds[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d122d8",
   "metadata": {},
   "source": [
    "# ğŸ§  Understanding TensorDataset and DataLoader in PyTorch\n",
    "\n",
    "In PyTorch, **`TensorDataset`** and **`DataLoader`** are used together to efficiently manage and feed data into models during training.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¹ 1. TensorDataset\n",
    "\n",
    "`TensorDataset` combines multiple tensors (like inputs and labels) into a single dataset object.  \n",
    "Each sample returned by indexing (`dataset[i]`) is a tuple containing corresponding elements from each tensor.\n",
    "\n",
    "### âœ¨ Example\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Sample input and output tensors\n",
    "X = torch.tensor([[1,2], [3,4], [5,6], [7,8]])\n",
    "y = torch.tensor([0, 1, 0, 1])\n",
    "\n",
    "# Combine into a dataset\n",
    "dataset = TensorDataset(X, y)\n",
    "\n",
    "# Accessing individual samples\n",
    "print(dataset[0])  # (tensor([1, 2]), tensor(0))\n",
    "print(dataset[1])  # (tensor([3, 4]), tensor(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2749700b",
   "metadata": {},
   "source": [
    "# âš™ï¸ Understanding DataLoader in PyTorch\n",
    "\n",
    "The **`DataLoader`** in PyTorch is used to load data efficiently during model training.  \n",
    "It wraps around a dataset (like a `TensorDataset` or a custom one) and provides features like **batching**, **shuffling**, and **parallel loading**.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¹ 1. Why Use DataLoader?\n",
    "\n",
    "When training deep learning models, we usually:\n",
    "- Donâ€™t feed all data at once (memory-heavy),\n",
    "- Instead, use **mini-batches** of data.\n",
    "\n",
    "`DataLoader` automates this process by:\n",
    "âœ… Splitting data into batches  \n",
    "âœ… Optionally shuffling each epoch  \n",
    "âœ… Feeding batches one by one to the model\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¹ 2. Basic Example\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Create some sample data\n",
    "X = torch.tensor([[1,2], [3,4], [5,6], [7,8], [9,10], [11,12]])\n",
    "y = torch.tensor([0, 1, 0, 1, 0, 1])\n",
    "\n",
    "# Create a TensorDataset\n",
    "dataset = TensorDataset(X, y)\n",
    "\n",
    "# Wrap it in a DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "782e94a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c246be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "train_d1 = DataLoader(train_ds,batch_size,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64cc55b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[102.,  43.,  37.],\n",
      "        [ 73.,  67.,  43.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [ 69.,  96.,  70.]])\n",
      "tensor([[ 22.,  37.],\n",
      "        [ 56.,  70.],\n",
      "        [119., 133.],\n",
      "        [119., 133.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "for xb,yb in train_d1:\n",
    "    print(xb)\n",
    "    print(yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed12811",
   "metadata": {},
   "source": [
    "it has randomly used 5 values because 5 is the batch size and we have set shuffle = true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0771fc6",
   "metadata": {},
   "source": [
    "         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "         â”‚        Raw Tensors           â”‚\n",
    "         â”‚   X â†’ Inputs,  y â†’ Labels    â”‚\n",
    "         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                        â”‚\n",
    "                        â–¼\n",
    "         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "         â”‚       TensorDataset          â”‚\n",
    "         â”‚ Pairs each (X[i], y[i])      â”‚\n",
    "         â”‚ â†’ [(xâ‚,yâ‚), (xâ‚‚,yâ‚‚), ...]    â”‚\n",
    "         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                        â”‚\n",
    "                        â–¼\n",
    "         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "         â”‚          DataLoader          â”‚\n",
    "         â”‚ - Shuffles data (if True)    â”‚\n",
    "         â”‚ - Splits into batches        â”‚\n",
    "         â”‚ - Prepares for iteration     â”‚\n",
    "         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                        â”‚\n",
    "                        â–¼\n",
    "      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "      â”‚        During Training Loop            â”‚\n",
    "      â”‚ for X_batch, y_batch in dataloader:    â”‚\n",
    "      â”‚     â†’ Model receives mini-batch        â”‚\n",
    "      â”‚     â†’ Forward pass                     â”‚\n",
    "      â”‚     â†’ Loss calculation                 â”‚\n",
    "      â”‚     â†’ Backward pass                    â”‚\n",
    "      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefca33f",
   "metadata": {},
   "source": [
    "**LINEAR MODULE** instead of initializing weights and biases manually we can define the model using the nn.Linear class which does it automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36122d5a",
   "metadata": {},
   "source": [
    "linear is one of the model in pytorch for linear regression moving on we have many like nn.convolution and all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fb4f173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.1108,  0.1982, -0.2847],\n",
      "        [-0.3553,  0.2865,  0.4303]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0232,  0.0763], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(3,2)\n",
    "print(model.weight)\n",
    "print(model.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7d1ade",
   "metadata": {},
   "source": [
    "pytoch models also have a helpful **.parameters** method which returns a list containing all the weights and bias matrices present in the model. for out linear regression model we have one wiehgt matrix and one bias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d429f609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.1108,  0.1982, -0.2847],\n",
       "         [-0.3553,  0.2865,  0.4303]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0232,  0.0763], requires_grad=True)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5c9719e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.1032, 11.8373],\n",
       "        [ 9.2809, 20.4943],\n",
       "        [19.6628, 32.5128],\n",
       "        [ 9.2690, -7.9239],\n",
       "        [ 6.7198, 33.1843],\n",
       "        [ 9.1032, 11.8373],\n",
       "        [ 9.2809, 20.4943],\n",
       "        [19.6628, 32.5128],\n",
       "        [ 9.2690, -7.9239],\n",
       "        [ 6.7198, 33.1843],\n",
       "        [ 9.1032, 11.8373],\n",
       "        [ 9.2809, 20.4943],\n",
       "        [19.6628, 32.5128],\n",
       "        [ 9.2690, -7.9239],\n",
       "        [ 6.7198, 33.1843]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generating predections\n",
    "preds = model(input)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1496e62",
   "metadata": {},
   "source": [
    "loss function with built function mse_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13c75fc",
   "metadata": {},
   "source": [
    "the nn.functional package contains many usefull loss functoins and several other utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95410ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78019ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ae0ab42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5598.7017, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = loss_fn(model(input),target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a1910f",
   "metadata": {},
   "source": [
    "****OPTIMIZERS**** instead of manually doing the gradient descent we use optim.SGD sgd is stochastic gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1923d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(model.parameters(),lr=1e-5)\n",
    "#defining optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bee33c",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "We are now ready to train the model. We'll follow the exact same process to implement gradient descent:\n",
    "\n",
    "1. Generate predictions\n",
    "\n",
    "2. Calculate the loss\n",
    "\n",
    "3. Compute gradients w.r.t the weights and biases\n",
    "\n",
    "4. Adjust the weights by subtracting a small quantity proportional to the gradient\n",
    "\n",
    "5. Reset the gradients to zero\n",
    "\n",
    "The only change is that we'll work batches of data, instead of processing the entire training data in every iteration. Let's define a utility function `fit` which trains the model for a given number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7be25719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to train the model\n",
    "def fit(num_epochs, model, loss_fn, opt):\n",
    "    \n",
    "    # Repeat for given number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Train with batches of data\n",
    "        for xb,yb in train_d1:\n",
    "            \n",
    "            # 1. Generate predictions\n",
    "            pred = model(xb)\n",
    "            \n",
    "            # 2. Calculate loss\n",
    "            loss = loss_fn(pred, yb)\n",
    "            \n",
    "            # 3. Compute gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # 4. Update parameters using gradients\n",
    "            opt.step()\n",
    "            \n",
    "            # 5. Reset the gradients to zero\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        # Print the progress\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e7992e",
   "metadata": {},
   "source": [
    "# âš™ï¸ Does the Optimizer Run Epochs Automatically in PyTorch?\n",
    "\n",
    "A common doubt when learning PyTorch is:\n",
    "\n",
    "> â“ *â€œDoes the optimizer (like `optim.SGD`) automatically run all the epochs and give optimized weights?â€*\n",
    "\n",
    "---\n",
    "\n",
    "## âŒ No â€” The Optimizer Doesnâ€™t Run Epochs by Itself\n",
    "\n",
    "The **optimizer** (e.g. `torch.optim.SGD`, `Adam`, etc.)  \n",
    "does **not** control training epochs or loops.\n",
    "\n",
    "It only performs **one single update step** each time you call:\n",
    "\n",
    "```python\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de433713",
   "metadata": {},
   "source": [
    "Instead of updating parameters (weights and biases) manually, we use opt.step to perform the update, and opt.zero_grad to reset the gradients to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d5517d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 220.6802\n",
      "Epoch [20/100], Loss: 163.3108\n",
      "Epoch [30/100], Loss: 154.2873\n",
      "Epoch [40/100], Loss: 38.2649\n",
      "Epoch [50/100], Loss: 4.8886\n",
      "Epoch [60/100], Loss: 57.2609\n",
      "Epoch [70/100], Loss: 60.3672\n",
      "Epoch [80/100], Loss: 15.8552\n",
      "Epoch [90/100], Loss: 26.3844\n",
      "Epoch [100/100], Loss: 18.5895\n"
     ]
    }
   ],
   "source": [
    "fit(100, model, loss_fn, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e51f01ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 58.6152,  70.8488],\n",
       "        [ 79.0505,  99.7146],\n",
       "        [123.4146, 134.3021],\n",
       "        [ 29.2151,  39.9129],\n",
       "        [ 91.6874, 115.7973],\n",
       "        [ 58.6152,  70.8488],\n",
       "        [ 79.0505,  99.7146],\n",
       "        [123.4146, 134.3021],\n",
       "        [ 29.2151,  39.9129],\n",
       "        [ 91.6874, 115.7973],\n",
       "        [ 58.6152,  70.8488],\n",
       "        [ 79.0505,  99.7146],\n",
       "        [123.4146, 134.3021],\n",
       "        [ 29.2151,  39.9129],\n",
       "        [ 91.6874, 115.7973]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate predictions\n",
    "preds = model(input)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dce1476a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.],\n",
       "        [ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.],\n",
       "        [ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare with targets\n",
    "target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
